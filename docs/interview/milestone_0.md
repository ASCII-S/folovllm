# Milestone 0 é¢è¯•æŒ‡å—

> æœ¬æ–‡æ¡£æ•´ç† M0 é˜¶æ®µå¯èƒ½é‡åˆ°çš„é¢è¯•é—®é¢˜åŠå›ç­”è¦ç‚¹

---

## ğŸ“‹ ç›®å½•

1. [é…ç½®ç³»ç»Ÿç›¸å…³](#1-é…ç½®ç³»ç»Ÿç›¸å…³)
2. [é‡‡æ ·ç­–ç•¥ç›¸å…³](#2-é‡‡æ ·ç­–ç•¥ç›¸å…³)
3. [æ•°æ®ç»“æ„è®¾è®¡](#3-æ•°æ®ç»“æ„è®¾è®¡)
4. [æ¨¡å‹åŠ è½½ç›¸å…³](#4-æ¨¡å‹åŠ è½½ç›¸å…³)
5. [ç³»ç»Ÿè®¾è®¡ç›¸å…³](#5-ç³»ç»Ÿè®¾è®¡ç›¸å…³)
6. [æ€§èƒ½ä¼˜åŒ–ç›¸å…³](#6-æ€§èƒ½ä¼˜åŒ–ç›¸å…³)

---

## 1. é…ç½®ç³»ç»Ÿç›¸å…³

### Q1.1: ä¸ºä»€ä¹ˆè¦è®¾è®¡åˆ†å±‚çš„é…ç½®ç³»ç»Ÿï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

1. **èŒè´£åˆ†ç¦»**ï¼š
   - ModelConfig ç®¡ç†æ¨¡å‹ç›¸å…³é…ç½®
   - CacheConfig ç®¡ç†ç¼“å­˜ç›¸å…³é…ç½®
   - SchedulerConfig ç®¡ç†è°ƒåº¦ç›¸å…³é…ç½®
   - æ¯ä¸ªé…ç½®ç±»èŒè´£å•ä¸€ï¼Œæ˜“äºç»´æŠ¤

2. **çµæ´»ç»„åˆ**ï¼š
   - å¯ä»¥ç‹¬ç«‹ä¿®æ”¹æŸä¸€å±‚é…ç½®è€Œä¸å½±å“å…¶ä»–å±‚
   - ä¾¿äºæµ‹è¯•ï¼ˆå¯ä»¥ mock ç‰¹å®šé…ç½®ï¼‰

3. **æ‰©å±•æ€§**ï¼š
   - æ–°å¢é…ç½®ç±»ä¸å½±å“ç°æœ‰ä»£ç 
   - ç¬¦åˆå¼€é—­åŸåˆ™ï¼ˆå¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å°é—­ï¼‰

4. **å¯è¯»æ€§**ï¼š
   - é…ç½®å±‚æ¬¡æ¸…æ™°ï¼Œå®¹æ˜“ç†è§£
   - ä¸ vLLM ç­‰æˆç†Ÿæ¡†æ¶å¯¹é½

**è¿½é—®ï¼šå¦‚ä½•ä¿è¯é…ç½®ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Ÿ**

**å›ç­”**ï¼š
```python
class EngineConfig:
    def __post_init__(self):
        # åœ¨é¡¶å±‚é…ç½®ä¸­åŒæ­¥å­é…ç½®
        if self.scheduler_config.max_model_len is None:
            self.scheduler_config.max_model_len = self.model_config.max_model_len
```

---

### Q1.2: ä¸ºä»€ä¹ˆä½¿ç”¨ dataclass è€Œä¸æ˜¯æ™®é€šç±»æˆ–å­—å…¸ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**vs æ™®é€šç±»**ï¼š
```python
# dataclass è‡ªåŠ¨ç”Ÿæˆ
@dataclass
class ModelConfig:
    model: str
    dtype: str = "auto"

# ç­‰ä»·äºæ™®é€šç±»çš„å¤§é‡ä»£ç 
class ModelConfig:
    def __init__(self, model: str, dtype: str = "auto"):
        self.model = model
        self.dtype = dtype
    
    def __repr__(self): ...
    def __eq__(self): ...
```

**vs å­—å…¸**ï¼š
- âœ… **ç±»å‹å®‰å…¨**ï¼šIDE å¯ä»¥æ£€æŸ¥ç±»å‹
- âœ… **è‡ªåŠ¨è¡¥å…¨**ï¼šIDE çŸ¥é“æœ‰å“ªäº›å­—æ®µ
- âœ… **éªŒè¯**ï¼š`__post_init__` å¯ä»¥éªŒè¯å‚æ•°
- âœ… **æ€§èƒ½**ï¼šæ¯”å­—å…¸è®¿é—®æ›´å¿«ï¼ˆå±æ€§è®¿é—®ï¼‰

**ç¤ºä¾‹**ï¼š
```python
# dataclass - IDE ä¼šæŠ¥é”™
config = ModelConfig(model=123)  # âŒ ç±»å‹é”™è¯¯

# dict - è¿è¡Œæ—¶æ‰å‘ç°é”™è¯¯
config = {"model": 123}  # âœ… æ²¡é—®é¢˜ï¼Œä½†åç»­ä¼šå‡ºé”™
```

---

### Q1.3: é…ç½®éªŒè¯ä¸ºä»€ä¹ˆæ”¾åœ¨ `__post_init__` è€Œä¸æ˜¯ `__init__`ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

dataclass çš„ç”Ÿæˆé¡ºåºï¼š
1. è‡ªåŠ¨ç”Ÿæˆçš„ `__init__` è®¾ç½®æ‰€æœ‰å­—æ®µ
2. è°ƒç”¨ç”¨æˆ·å®šä¹‰çš„ `__post_init__`

**å¥½å¤„**ï¼š
- æ‰€æœ‰å­—æ®µéƒ½å·²åˆå§‹åŒ–ï¼Œå¯ä»¥è®¿é—®ä»»ä½•å­—æ®µ
- å¯ä»¥è¿›è¡Œè·¨å­—æ®µéªŒè¯
- ä¸éœ€è¦æ‰‹å†™ `__init__`

**ç¤ºä¾‹**ï¼š
```python
@dataclass
class SamplingParams:
    n: int = 1
    best_of: Optional[int] = None
    
    def __post_init__(self):
        # æ­¤æ—¶ self.n å’Œ self.best_of éƒ½å·²è®¾ç½®
        if self.best_of is None:
            self.best_of = self.n
        
        # è·¨å­—æ®µéªŒè¯
        if self.best_of < self.n:
            raise ValueError(f"best_of ({self.best_of}) must be >= n ({self.n})")
```

---

## 2. é‡‡æ ·ç­–ç•¥ç›¸å…³

### Q2.1: è§£é‡Š Temperatureã€Top-kã€Top-p çš„åŒºåˆ«å’Œä½¿ç”¨åœºæ™¯

**å›ç­”è¦ç‚¹**ï¼š

**Temperature**ï¼š
- **åŸç†**ï¼šè°ƒæ•´æ¦‚ç‡åˆ†å¸ƒçš„é™¡å³­ç¨‹åº¦
- **å…¬å¼**ï¼š`logits_scaled = logits / temperature`
- **æ•ˆæœ**ï¼š
  - `< 1.0`: æ›´ç¡®å®šï¼ˆåˆ†å¸ƒæ›´é™¡ï¼‰
  - `= 1.0`: åŸå§‹åˆ†å¸ƒ
  - `> 1.0`: æ›´éšæœºï¼ˆåˆ†å¸ƒæ›´å¹³ï¼‰
- **ä½¿ç”¨**ï¼šæ§åˆ¶è¾“å‡ºçš„åˆ›é€ æ€§

**Top-k**ï¼š
- **åŸç†**ï¼šåªä»æ¦‚ç‡æœ€é«˜çš„ k ä¸ª token ä¸­é‡‡æ ·
- **ä¼˜ç‚¹**ï¼šè¿‡æ»¤ä½æ¦‚ç‡å™ªéŸ³
- **ç¼ºç‚¹**ï¼šå›ºå®š k å€¼ï¼Œä¸é€‚åº”ä¸åŒçš„åˆ†å¸ƒ
- **ä½¿ç”¨**ï¼šä¸€èˆ¬è®¾ç½® k=50

**Top-p (Nucleus)**ï¼š
- **åŸç†**ï¼šé€‰æ‹©ç´¯ç§¯æ¦‚ç‡è¾¾åˆ° p çš„æœ€å° token é›†
- **ä¼˜ç‚¹**ï¼šåŠ¨æ€è°ƒæ•´å€™é€‰é›†å¤§å°
- **æ•ˆæœ**ï¼š
  - åˆ†å¸ƒå¹³ç¼“æ—¶ï¼šåŒ…å«æ›´å¤šå€™é€‰
  - åˆ†å¸ƒé™¡å³­æ—¶ï¼šåªåŒ…å«é«˜æ¦‚ç‡ token
- **ä½¿ç”¨**ï¼šp=0.9 æˆ– 0.95

**ç»„åˆä½¿ç”¨**ï¼š
```python
SamplingParams(
    temperature=0.8,  # å¢åŠ éšæœºæ€§
    top_k=50,         # è¿‡æ»¤å™ªéŸ³
    top_p=0.95        # åŠ¨æ€å€™é€‰é›†
)
# æ‰§è¡Œé¡ºåºï¼štemperature â†’ top_k â†’ top_p â†’ sample
```

**è¿½é—®ï¼šä¸ºä»€ä¹ˆè¦ç»„åˆä½¿ç”¨ï¼Ÿ**

**å›ç­”**ï¼š
- Temperature è°ƒæ•´æ•´ä½“éšæœºæ€§
- Top-k å»é™¤æ˜æ˜¾çš„åå€™é€‰
- Top-p åœ¨å‰©ä½™å€™é€‰ä¸­åŠ¨æ€é€‰æ‹©
- ä¸‰è€…äº’è¡¥ï¼Œæ•ˆæœæœ€ä½³

---

### Q2.2: Greedy Sampling å’Œ Beam Search çš„åŒºåˆ«ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**Greedy Sampling**ï¼š
```python
# æ¯æ­¥é€‰æ‹©æœ€ä¼˜
step 1: token_a (prob=0.6) âœ“
step 2: token_b (prob=0.5) âœ“
step 3: token_c (prob=0.4) âœ“
æ€»åˆ†æ•°: 0.6 Ã— 0.5 Ã— 0.4 = 0.12
```

**Beam Search** (beam_size=3):
```python
# ç»´æŠ¤ 3 ä¸ªå€™é€‰åºåˆ—
step 1: [token_a, token_b, token_c]  # å‰3ä¸ªæœ€ä¼˜
step 2: 
  token_a â†’ [token_x, token_y, token_z]
  token_b â†’ [token_p, token_q, token_r]
  token_c â†’ [token_m, token_n, token_o]
  # ä» 9 ä¸ªå€™é€‰ä¸­é€‰å‰ 3 ä¸ªæœ€ä¼˜
step 3: ...
```

**åŒºåˆ«**ï¼š

| ç»´åº¦     | Greedy           | Beam Search        |
| -------- | ---------------- | ------------------ |
| æœç´¢ç©ºé—´ | è´ªå¿ƒï¼ˆå±€éƒ¨æœ€ä¼˜ï¼‰ | å¹¿åº¦ä¼˜å…ˆï¼ˆæ›´å…¨å±€ï¼‰ |
| è®¡ç®—é‡   | O(1)             | O(beam_size)       |
| ç»“æœè´¨é‡ | å¯èƒ½æ¬¡ä¼˜         | é€šå¸¸æ›´å¥½           |
| å¤šæ ·æ€§   | ä½               | ä¸­ç­‰               |
| ä½¿ç”¨åœºæ™¯ | é€Ÿåº¦ä¼˜å…ˆ         | è´¨é‡ä¼˜å…ˆï¼ˆç¿»è¯‘ï¼‰   |

**è¿½é—®ï¼šä¸ºä»€ä¹ˆ Beam Search åœ¨å¯¹è¯ç”Ÿæˆä¸­æ•ˆæœä¸å¥½ï¼Ÿ**

**å›ç­”**ï¼š
- Beam Search å€¾å‘äºç”Ÿæˆå®‰å…¨ã€é€šç”¨çš„å›å¤
- ç¼ºä¹å¤šæ ·æ€§å’Œåˆ›é€ æ€§
- å¯¹è¯éœ€è¦éšæœºé‡‡æ ·å¢åŠ è¶£å‘³æ€§

---

### Q2.3: å¦‚ä½•å®ç° n > 1 çš„å¹¶è¡Œé‡‡æ ·ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**æ–¹æ³•ä¸€ï¼šç‹¬ç«‹é‡‡æ ·**ï¼ˆFoloVLLM å½“å‰å®ç°ï¼‰
```python
# åˆ›å»º n ä¸ªç‹¬ç«‹åºåˆ—
for i in range(n):
    seq = Sequence(...)
    sequences.append(seq)

# æ¯ä¸ªåºåˆ—ç‹¬ç«‹é‡‡æ ·
for seq in sequences:
    next_token = sample(logits, temperature, top_p, top_k)
    seq.add_token_id(next_token)
```

**æ–¹æ³•äºŒï¼šBest-of-N**ï¼ˆæ›´é«˜çº§ï¼‰
```python
# ç”Ÿæˆ best_of ä¸ªå€™é€‰
n=3, best_of=5

# 1. ç”Ÿæˆ 5 ä¸ªåºåˆ—
sequences = [Sequence(...) for _ in range(5)]

# 2. å¹¶è¡Œç”Ÿæˆ
for seq in sequences:
    generate(seq)

# 3. æŒ‰ç´¯ç§¯ log æ¦‚ç‡æ’åº
sequences.sort(key=lambda s: s.cumulative_logprob, reverse=True)

# 4. è¿”å›å‰ 3 ä¸ª
return sequences[:3]
```

**ä¼˜åŒ–**ï¼š
- å…±äº« prompt çš„ KV Cache
- åªåœ¨ decode é˜¶æ®µç‹¬ç«‹è®¡ç®—
- å‡å°‘é‡å¤è®¡ç®—

**è¿½é—®ï¼šå¦‚ä½•å…±äº« prompt çš„ KV Cacheï¼Ÿ**

**å›ç­”**ï¼ˆé¢„å‘Š M3ï¼‰ï¼š
```python
# æ‰€æœ‰åºåˆ—å…±äº« prompt çš„ KV Cache blocks
for seq in sequences:
    seq.block_ids[:prompt_blocks] = shared_blocks  # å…±äº«
    seq.block_ids[prompt_blocks:] = allocate_new_blocks()  # ç‹¬ç«‹
```

---

## 3. æ•°æ®ç»“æ„è®¾è®¡

### Q3.1: ä¸ºä»€ä¹ˆéœ€è¦ Requestã€Sequenceã€SequenceData ä¸‰å±‚æŠ½è±¡ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**Request**ï¼ˆè¯·æ±‚çº§åˆ«ï¼‰ï¼š
- ç®¡ç†ä¸€ä¸ªæ¨ç†è¯·æ±‚çš„æ‰€æœ‰åºåˆ—
- åŒ…å«å…±äº«ä¿¡æ¯ï¼špromptã€sampling_params
- æä¾›è¯·æ±‚çº§åˆ«çš„æ“ä½œï¼šis_finished()ã€get_seqs()

**Sequence**ï¼ˆåºåˆ—çº§åˆ«ï¼‰ï¼š
- ä¸€ä¸ªç‹¬ç«‹çš„ç”Ÿæˆåºåˆ—
- ç®¡ç†åºåˆ—çŠ¶æ€ï¼šWAITING/RUNNING/FINISHED
- ç®¡ç†åºåˆ—èµ„æºï¼šKV Cache blocksï¼ˆM3ï¼‰
- æä¾›åºåˆ—çº§åˆ«çš„æ“ä½œï¼šadd_token_id()ã€fork()

**SequenceData**ï¼ˆæ•°æ®çº§åˆ«ï¼‰ï¼š
- çº¯æ•°æ®å®¹å™¨ï¼šprompt_token_idsã€output_token_ids
- ä¸åŒ…å«çŠ¶æ€å’Œé€»è¾‘
- ä¾¿äºåºåˆ—åŒ–å’Œä¼ è¾“

**ç±»æ¯”**ï¼š
```
Request   = è®¢å•
Sequence  = è®¢å•é¡¹
SequenceData = å•†å“ä¿¡æ¯
```

**å¥½å¤„**ï¼š
- èŒè´£æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤
- ä¾¿äºæ‰©å±•ï¼ˆå¦‚æ·»åŠ çŠ¶æ€ã€èµ„æºç®¡ç†ï¼‰
- ç¬¦åˆå•ä¸€èŒè´£åŸåˆ™

---

### Q3.2: Sequence çš„ fork() æ–¹æ³•æœ‰ä»€ä¹ˆç”¨ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**ç”¨é€”**ï¼š

1. **Beam Search**ï¼š
```python
# æ‰©å±•å€™é€‰
beam = [seq1, seq2, seq3]
new_beam = []
for seq in beam:
    for token in top_k_tokens:
        new_seq = seq.fork(f"{seq.seq_id}-{token}")
        new_seq.add_token_id(token)
        new_beam.append(new_seq)
# ä¿ç•™æœ€ä¼˜çš„ beam_size ä¸ª
```

2. **Speculative Decoding**ï¼š
```python
# Draft model ç”Ÿæˆæ¨æµ‹åºåˆ—
draft_seq = seq.fork("draft")
# éªŒè¯æ¨æµ‹ï¼Œä¸ä¿®æ”¹åŸåºåˆ—
```

3. **Parallel Sampling**ï¼š
```python
# ä»ä¸€ä¸ªåºåˆ—æ´¾ç”Ÿå¤šä¸ªç‹¬ç«‹åºåˆ—
sequences = [seq.fork(f"seq-{i}") for i in range(n)]
```

**å…³é”®**ï¼šæ·±æ‹·è´
```python
def fork(self, new_seq_id: str) -> "Sequence":
    new_data = SequenceData(
        prompt_token_ids=self.data.prompt_token_ids.copy(),  # æ·±æ‹·è´
        output_token_ids=self.data.output_token_ids.copy(),
    )
    # ä¿®æ”¹ fork çš„åºåˆ—ä¸å½±å“åŸåºåˆ—
```

**è¿½é—®ï¼šä¸ºä»€ä¹ˆè¦æ·±æ‹·è´ï¼Ÿ**

**å›ç­”**ï¼š
```python
# å¦‚æœæµ…æ‹·è´
seq1 = Sequence(...)
seq2 = seq1.fork("seq2")
seq2.output_token_ids.append(100)
# âŒ seq1 ä¹Ÿä¼šè¢«ä¿®æ”¹ï¼

# æ·±æ‹·è´é¿å…å…±äº«çŠ¶æ€
seq2.data.output_token_ids = seq1.data.output_token_ids.copy()
seq2.output_token_ids.append(100)
# âœ… seq1 ä¸å—å½±å“
```

---

### Q3.3: åºåˆ—çŠ¶æ€æœºæ˜¯å¦‚ä½•è®¾è®¡çš„ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**çŠ¶æ€è½¬æ¢å›¾**ï¼š
```
    WAITING
       â†“ schedule()
    RUNNING
    â†™     â†“     â†˜
SWAPPED  step()  FINISHED_*
    â†“         â†—
    â””â”€ resume()
```

**çŠ¶æ€è¯´æ˜**ï¼š
- `WAITING`: åœ¨ç­‰å¾…é˜Ÿåˆ—ï¼Œç­‰å¾…è¢«è°ƒåº¦
- `RUNNING`: æ­£åœ¨ç”Ÿæˆ token
- `SWAPPED`: è¢«æ¢å‡ºåˆ° CPUï¼ˆæ˜¾å­˜ä¸è¶³æ—¶ï¼‰
- `FINISHED_STOPPED`: é‡åˆ°åœæ­¢æ¡ä»¶ï¼ˆEOSã€stop stringï¼‰
- `FINISHED_LENGTH_CAPPED`: è¾¾åˆ° max_tokens
- `FINISHED_ABORTED`: ç”¨æˆ·å–æ¶ˆ

**çŠ¶æ€æ£€æŸ¥**ï¼š
```python
class SequenceStatus(Enum):
    def is_finished(self) -> bool:
        return self in [
            SequenceStatus.FINISHED_STOPPED,
            SequenceStatus.FINISHED_LENGTH_CAPPED,
            SequenceStatus.FINISHED_ABORTED,
        ]
```

**ä½¿ç”¨**ï¼š
```python
# è°ƒåº¦å™¨æ ¹æ®çŠ¶æ€å†³ç­–
if seq.status == SequenceStatus.WAITING:
    schedule_seq(seq)
elif seq.status == SequenceStatus.RUNNING:
    if seq.is_finished():
        remove_from_running(seq)
```

---

## 4. æ¨¡å‹åŠ è½½ç›¸å…³

### Q4.1: ä¸åŒ dtype çš„åŒºåˆ«å’Œé€‰æ‹©ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**æ•°æ®ç±»å‹å¯¹æ¯”**ï¼š

| dtype    | ä½æ•° | èŒƒå›´ | ç²¾åº¦ | æ˜¾å­˜ | é€Ÿåº¦ | ä½¿ç”¨åœºæ™¯       |
| -------- | ---- | ---- | ---- | ---- | ---- | -------------- |
| float32  | 32   | å¤§   | é«˜   | åŸºå‡† | æ…¢   | è®­ç»ƒã€ç§‘å­¦è®¡ç®— |
| float16  | 16   | å°   | ä¸­   | 50%  | å¿«   | æ¨ç†ï¼ˆé€šç”¨ï¼‰   |
| bfloat16 | 16   | å¤§   | ä½   | 50%  | å¿«   | æ¨ç†ï¼ˆæ–°ç¡¬ä»¶ï¼‰ |

**FP16 vs BF16**ï¼š
```
FP32:  1 bit (ç¬¦å·) + 8 bits (æŒ‡æ•°) + 23 bits (å°¾æ•°)
FP16:  1 bit (ç¬¦å·) + 5 bits (æŒ‡æ•°) + 10 bits (å°¾æ•°)
BF16:  1 bit (ç¬¦å·) + 8 bits (æŒ‡æ•°) + 7 bits (å°¾æ•°)
```

- **FP16**ï¼šç²¾åº¦é«˜ï¼Œä½†èŒƒå›´å°ï¼Œå®¹æ˜“æº¢å‡º
- **BF16**ï¼šèŒƒå›´å¤§ï¼ˆä¸ FP32 ç›¸åŒï¼‰ï¼Œä½†ç²¾åº¦ä½

**é€‰æ‹©ç­–ç•¥**ï¼š
```python
def choose_dtype(model_name, hardware):
    if "è®­ç»ƒ" in task:
        return torch.float32
    
    if "A100" in hardware or "H100" in hardware:
        return torch.bfloat16  # æ–°ç¡¬ä»¶æ”¯æŒ
    
    if "V100" in hardware:
        return torch.float16  # æ—§ç¡¬ä»¶
    
    if "CPU" in hardware:
        return torch.float32  # CPU ä¸æ”¯æŒ FP16
```

**è¿½é—®ï¼šä¸ºä»€ä¹ˆæ¨¡å‹æ¨ç†å¯ä»¥ç”¨ FP16ï¼Ÿ**

**å›ç­”**ï¼š
- æ¨ç†ä¸éœ€è¦æ¢¯åº¦ï¼Œæ•°å€¼ç¨³å®šæ€§è¦æ±‚ä½
- Transformer å¯¹ç²¾åº¦ä¸æ•æ„Ÿ
- å®éªŒè¡¨æ˜ FP16 æ¨ç†ç²¾åº¦æŸå¤± < 1%

---

### Q4.2: ä¸ºä»€ä¹ˆ tokenizer çš„ padding_side è¦è®¾ç½®ä¸º leftï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**ç”Ÿæˆä»»åŠ¡çš„ç‰¹ç‚¹**ï¼š
- éœ€è¦çŸ¥é“æ¯ä¸ªåºåˆ—çš„"ç»“å°¾"åœ¨å“ªé‡Œ
- ä»ç»“å°¾å¼€å§‹ç”Ÿæˆæ–° token

**Left Padding**ï¼ˆæ¨èï¼‰ï¼š
```python
# Batch
Seq 1: [PAD][PAD] Hello world
Seq 2: [PAD] Hello world !
         â†“
# ç”Ÿæˆæ—¶ï¼Œattention mask ä¿è¯ PAD ä¸å‚ä¸è®¡ç®—
# æ–° token æ·»åŠ åœ¨å³ä¾§ï¼ˆå·²å¯¹é½ï¼‰
Seq 1: [PAD][PAD] Hello world <new>
Seq 2: [PAD] Hello world ! <new>
                            â†‘ ä½ç½®å¯¹é½
```

**Right Padding**ï¼ˆä¸æ¨èç”Ÿæˆï¼‰ï¼š
```python
# Batch
Seq 1: Hello world [PAD][PAD]
Seq 2: Hello world ! [PAD]
         â†“
# ç”Ÿæˆæ—¶ï¼Œæ¯ä¸ªåºåˆ—çš„"ç»“å°¾"ä½ç½®ä¸åŒ
Seq 1: Hello world [PAD][PAD]  # åœ¨ä½ç½® 2
Seq 2: Hello world ! [PAD]      # åœ¨ä½ç½® 3
# éœ€è¦é¢å¤–å¤„ç†æ¥æ‰¾åˆ°æ­£ç¡®çš„ç”Ÿæˆä½ç½®
```

**å®ç°**ï¼š
```python
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    padding_side="left",  # â† å…³é”®
)
```

**è¿½é—®ï¼šåˆ†ç±»ä»»åŠ¡ä¸ºä»€ä¹ˆç”¨ Right Paddingï¼Ÿ**

**å›ç­”**ï¼š
```python
# åˆ†ç±»ä»»åŠ¡å…³æ³¨æœ€åä¸€ä¸ªçœŸå® token
Seq 1: [CLS] Hello world [SEP] [PAD]
                           â†‘ è¿™é‡Œåšåˆ†ç±»
Seq 2: [CLS] Hello world ! [SEP]
                            â†‘ è¿™é‡Œåšåˆ†ç±»
# Right padding è®©åˆ†ç±»ä½ç½®æ›´æ¥è¿‘
```

---

### Q4.3: å¦‚ä½•å¤„ç†æ¨¡å‹å’Œ tokenizer ä¸åŒ¹é…çš„æƒ…å†µï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**é—®é¢˜åœºæ™¯**ï¼š
- ä½¿ç”¨äº†ä¸åŒçš„ tokenizer
- Tokenizer ç¼ºå°‘ç‰¹æ®Š token
- Vocab size ä¸åŒ¹é…

**å¤„ç†ç­–ç•¥**ï¼š

**1. è‡ªåŠ¨è®¾ç½® pad_token**ï¼š
```python
if tokenizer.pad_token is None:
    if tokenizer.eos_token:
        tokenizer.pad_token = tokenizer.eos_token  # å¤ç”¨ EOS
    else:
        tokenizer.add_special_tokens({"pad_token": "[PAD]"})  # æ–°å»º
        # éœ€è¦ resize æ¨¡å‹çš„ embedding
        model.resize_token_embeddings(len(tokenizer))
```

**2. æ£€æŸ¥ vocab size**ï¼š
```python
model_vocab_size = model.config.vocab_size
tokenizer_vocab_size = len(tokenizer)

if model_vocab_size != tokenizer_vocab_size:
    logger.warning(f"Vocab size mismatch: {model_vocab_size} vs {tokenizer_vocab_size}")
    # è°ƒæ•´æ¨¡å‹
    model.resize_token_embeddings(tokenizer_vocab_size)
```

**3. éªŒè¯ç‰¹æ®Š token**ï¼š
```python
required_tokens = ["bos_token", "eos_token", "pad_token"]
for token_name in required_tokens:
    if getattr(tokenizer, token_name) is None:
        logger.warning(f"Missing {token_name}")
```

---

## 5. ç³»ç»Ÿè®¾è®¡ç›¸å…³

### Q5.1: å¦‚æœè¦æ”¯æŒå¤š GPUï¼Œé…ç½®ç³»ç»Ÿéœ€è¦æ€ä¹ˆæ”¹ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**å½“å‰å• GPU è®¾è®¡**ï¼š
```python
@dataclass
class ModelConfig:
    model: str
    dtype: str = "auto"
    # æ²¡æœ‰ GPU ç›¸å…³é…ç½®
```

**å¤š GPU æ‰©å±•**ï¼š
```python
@dataclass
class ParallelConfig:
    """å¹¶è¡Œé…ç½®"""
    tensor_parallel_size: int = 1  # å¼ é‡å¹¶è¡Œï¼ˆæ¨¡å‹åˆ‡åˆ†ï¼‰
    pipeline_parallel_size: int = 1  # æµæ°´çº¿å¹¶è¡Œï¼ˆå±‚åˆ‡åˆ†ï¼‰
    data_parallel_size: int = 1  # æ•°æ®å¹¶è¡Œï¼ˆbatch åˆ‡åˆ†ï¼‰
    
    def get_world_size(self) -> int:
        return (self.tensor_parallel_size * 
                self.pipeline_parallel_size * 
                self.data_parallel_size)

@dataclass
class EngineConfig:
    model_config: ModelConfig
    parallel_config: ParallelConfig  # æ–°å¢
    # ...
```

**ä½¿ç”¨**ï¼š
```python
# 2-GPU å¼ é‡å¹¶è¡Œ
config = EngineConfig(
    model_config=ModelConfig(...),
    parallel_config=ParallelConfig(tensor_parallel_size=2)
)
```

**è¿½é—®ï¼šè¿™ä¸‰ç§å¹¶è¡Œçš„åŒºåˆ«ï¼Ÿ**

**å›ç­”**ï¼š
- **Tensor Parallel**: æŠŠæ¯å±‚å‚æ•°åˆ‡åˆ†åˆ°å¤šä¸ª GPUï¼ˆéœ€è¦é€šä¿¡ï¼‰
- **Pipeline Parallel**: æŠŠä¸åŒå±‚æ”¾åˆ°ä¸åŒ GPUï¼ˆå±‚é—´é€šä¿¡ï¼‰
- **Data Parallel**: æ¯ä¸ª GPU æœ‰å®Œæ•´æ¨¡å‹ï¼Œå¤„ç†ä¸åŒ batch

---

### Q5.2: å¦‚ä½•è®¾è®¡æ‰èƒ½æ–¹ä¾¿åœ°æ·»åŠ æ–°çš„é…ç½®é¡¹ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**åŸåˆ™**ï¼šå¼€é—­åŸåˆ™ï¼ˆå¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å°é—­ï¼‰

**1. ä½¿ç”¨å¯é€‰å‚æ•°**ï¼š
```python
@dataclass
class CacheConfig:
    block_size: int = 16
    gpu_memory_utilization: float = 0.9
    # æ–°å¢é…ç½®ï¼ˆå‘åå…¼å®¹ï¼‰
    enable_prefix_caching: bool = False  # é»˜è®¤å€¼ä¿æŒå…¼å®¹
    prefix_cache_size: Optional[int] = None  # å¯é€‰
```

**2. ä½¿ç”¨ Union ç±»å‹**ï¼š
```python
from typing import Union

@dataclass
class ModelConfig:
    # æ”¯æŒå¤šç§è¾“å…¥ç±»å‹
    dtype: Union[str, torch.dtype] = "auto"
    
    def __post_init__(self):
        # ç»Ÿä¸€è½¬æ¢
        if isinstance(self.dtype, str):
            self.torch_dtype = parse_dtype(self.dtype)
```

**3. ä½¿ç”¨é…ç½®å­—å…¸**ï¼š
```python
@dataclass
class EngineConfig:
    # é¢„ç•™æ‰©å±•å­—æ®µ
    extra_config: Dict[str, Any] = field(default_factory=dict)
    
    def get(self, key: str, default=None):
        return self.extra_config.get(key, default)
```

**4. ç‰ˆæœ¬åŒ–é…ç½®**ï¼š
```python
@dataclass
class EngineConfig:
    config_version: str = "1.0"
    
    @classmethod
    def from_dict(cls, config_dict: dict):
        version = config_dict.get("config_version", "1.0")
        if version == "1.0":
            return cls(**config_dict)
        elif version == "2.0":
            # å¤„ç†ç‰ˆæœ¬è¿ç§»
            return cls._migrate_v1_to_v2(config_dict)
```

---

## 6. æ€§èƒ½ä¼˜åŒ–ç›¸å…³

### Q6.1: å¦‚ä½•å‡å°‘é…ç½®éªŒè¯çš„å¼€é”€ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**é—®é¢˜**ï¼šæ¯æ¬¡åˆ›å»ºé…ç½®éƒ½è¦éªŒè¯ï¼Œå¯èƒ½å½±å“æ€§èƒ½

**ä¼˜åŒ–ç­–ç•¥**ï¼š

**1. æ‡’éªŒè¯**ï¼š
```python
@dataclass
class CacheConfig:
    block_size: int = 16
    _validated: bool = field(default=False, init=False)
    
    def validate(self):
        """å»¶è¿Ÿåˆ°å®é™…ä½¿ç”¨æ—¶éªŒè¯"""
        if self._validated:
            return
        
        if self.block_size <= 0:
            raise ValueError(...)
        
        self._validated = True
```

**2. ç¼“å­˜éªŒè¯ç»“æœ**ï¼š
```python
@dataclass
class SamplingParams:
    temperature: float = 1.0
    _sampling_type: Optional[SamplingType] = field(default=None, init=False)
    
    @property
    def sampling_type(self) -> SamplingType:
        """ç¼“å­˜è®¡ç®—ç»“æœ"""
        if self._sampling_type is None:
            self._sampling_type = self._compute_sampling_type()
        return self._sampling_type
```

**3. æ‰¹é‡éªŒè¯**ï¼š
```python
# ä¸è¦è¿™æ ·
for config in configs:
    config.validate()  # æ¯ä¸ªéƒ½éªŒè¯

# åº”è¯¥è¿™æ ·
EngineConfig.validate_batch(configs)  # æ‰¹é‡éªŒè¯ï¼Œå…±äº«æ£€æŸ¥
```

**è¿½é—®ï¼šè¿™æ ·åšçš„æƒè¡¡æ˜¯ä»€ä¹ˆï¼Ÿ**

**å›ç­”**ï¼š
- **ä¼˜ç‚¹**ï¼šæ€§èƒ½æ›´å¥½ï¼Œç‰¹åˆ«æ˜¯é¢‘ç¹åˆ›å»ºé…ç½®æ—¶
- **ç¼ºç‚¹**ï¼šé”™è¯¯å‘ç°å»¶è¿Ÿï¼Œå¯èƒ½åœ¨è¿è¡Œæ—¶æ‰å‘ç°é…ç½®é”™è¯¯
- **å»ºè®®**ï¼šå…³é”®é…ç½®ï¼ˆå¦‚å®‰å…¨ç›¸å…³ï¼‰ç«‹å³éªŒè¯ï¼Œæ€§èƒ½ç›¸å…³é…ç½®å»¶è¿ŸéªŒè¯

---

### Q6.2: ä¸ºä»€ä¹ˆ token_ids ä½¿ç”¨ List è€Œä¸æ˜¯ Tensorï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**åŠ¨æ€å¢é•¿**ï¼š
```python
# List - åŠ¨æ€æ·»åŠ å¾ˆæ–¹ä¾¿
output_token_ids = []
for _ in range(max_tokens):
    token = generate_next_token()
    output_token_ids.append(token)  # O(1) å‡æ‘Š

# Tensor - éœ€è¦é¢„åˆ†é…æˆ–é‡æ–°åˆ†é…
output_tokens = torch.zeros(max_tokens, dtype=torch.long)
for i in range(actual_len):
    output_tokens[i] = generate_next_token()
# æˆ–è€…
output_tokens = torch.cat([output_tokens, new_token.unsqueeze(0)])  # æ¯æ¬¡éƒ½å¤åˆ¶
```

**å†…å­˜æ•ˆç‡**ï¼š
```python
# List: åªå­˜å‚¨å®é™…ç”Ÿæˆçš„ token
[1, 2, 3]  # 3 ä¸ªæ•´æ•°

# Tensor: é¢„åˆ†é…æœ€å¤§é•¿åº¦
tensor([1, 2, 3, 0, 0, 0, ...])  # æµªè´¹å†…å­˜
```

**ä½•æ—¶è½¬æ¢ä¸º Tensor**ï¼š
```python
# æ‰¹å¤„ç†æ—¶æ‰è½¬æ¢
def prepare_batch(sequences):
    # è½¬æ¢ä¸º padded tensor
    token_ids_list = [seq.get_token_ids() for seq in sequences]
    return pad_sequence(token_ids_list)  # â†’ Tensor
```

**è¿½é—®ï¼šList çš„ç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ**

**å›ç­”**ï¼š
- ä¸èƒ½ç›´æ¥ç”¨äºæ¨¡å‹è®¡ç®—ï¼ˆéœ€è¦è½¬æ¢ï¼‰
- å•ä¸ªå…ƒç´ è®¿é—®æ¯” Tensor æ…¢
- ä½†åœ¨åŠ¨æ€å¢é•¿åœºæ™¯ä¸‹ï¼Œä¼˜ç‚¹å¤§äºç¼ºç‚¹

---

### Q6.3: å¦‚ä½•ä¼˜åŒ–å¤§é‡ Sequence å¯¹è±¡çš„åˆ›å»ºï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**é—®é¢˜**ï¼šåˆ›å»ºå¤§é‡åºåˆ—å¯¹è±¡å¼€é”€å¤§

**ä¼˜åŒ–æ–¹æ³•**ï¼š

**1. å¯¹è±¡æ± **ï¼š
```python
class SequencePool:
    def __init__(self, pool_size=1000):
        self.pool = [Sequence(...) for _ in range(pool_size)]
        self.free_list = list(range(pool_size))
    
    def acquire(self) -> Sequence:
        if not self.free_list:
            # æ± æ»¡ï¼Œåˆ›å»ºæ–°å¯¹è±¡
            return Sequence(...)
        idx = self.free_list.pop()
        seq = self.pool[idx]
        seq.reset()  # é‡ç½®çŠ¶æ€
        return seq
    
    def release(self, seq: Sequence):
        # å½’è¿˜åˆ°æ± ä¸­
        self.free_list.append(seq.pool_index)
```

**2. å»¶è¿Ÿåˆå§‹åŒ–**ï¼š
```python
@dataclass
class Sequence:
    # åªåœ¨éœ€è¦æ—¶åˆ›å»º
    _cached_token_ids: Optional[List[int]] = None
    
    def get_token_ids(self) -> List[int]:
        if self._cached_token_ids is None:
            self._cached_token_ids = (
                self.data.prompt_token_ids + 
                self.data.output_token_ids
            )
        return self._cached_token_ids
```

**3. æ‰¹é‡åˆ›å»º**ï¼š
```python
def create_sequences_batch(n: int, config: SamplingParams):
    # ä¸€æ¬¡æ€§åˆ†é…å†…å­˜
    sequences = []
    base_data = SequenceData(...)
    
    for i in range(n):
        # æµ…æ‹·è´ + æ·±æ‹·è´éœ€è¦ç‹¬ç«‹çš„éƒ¨åˆ†
        seq = Sequence(
            seq_id=f"seq-{i}",
            data=base_data.copy(),  # åªæ‹·è´å¿…è¦çš„
            sampling_params=config,  # å…±äº«ä¸å˜çš„éƒ¨åˆ†
        )
        sequences.append(seq)
    
    return sequences
```

---

## æ€»ç»“ï¼šé¢è¯•å‡†å¤‡å»ºè®®

### é‡ç‚¹æŒæ¡

1. **é…ç½®ç³»ç»Ÿ**ï¼š
   - ä¸ºä»€ä¹ˆåˆ†å±‚ï¼Ÿ
   - ä¸ºä»€ä¹ˆç”¨ dataclassï¼Ÿ
   - å¦‚ä½•æ‰©å±•ï¼Ÿ

2. **é‡‡æ ·ç­–ç•¥**ï¼š
   - Temperatureã€Top-kã€Top-p åŸç†
   - ç»„åˆä½¿ç”¨çš„ç†ç”±
   - ä¸åŒä»»åŠ¡çš„é€‰æ‹©

3. **æ•°æ®ç»“æ„**ï¼š
   - ä¸‰å±‚æŠ½è±¡çš„ç†ç”±
   - çŠ¶æ€æœºè®¾è®¡
   - Fork æœºåˆ¶

4. **ç³»ç»Ÿè®¾è®¡**ï¼š
   - å¦‚ä½•æ‰©å±•åˆ°å¤š GPU
   - é…ç½®ç®¡ç†æœ€ä½³å®è·µ
   - æ€§èƒ½ä¼˜åŒ–æƒè¡¡

### æ·±å…¥å­¦ä¹ 

- é˜…è¯» vLLM æºç å¯¹æ¯”å®ç°å·®å¼‚
- å®éªŒä¸åŒé…ç½®çš„æ€§èƒ½å½±å“
- æ€è€ƒæœªæ¥åŠŸèƒ½çš„æ‰©å±•æ–¹å¼

### é¢è¯•æŠ€å·§

1. **ç»“æ„åŒ–å›ç­”**ï¼šå…ˆæ€»ååˆ†ï¼Œåˆ—ä¸¾è¦ç‚¹
2. **ä¸¾ä¾‹è¯´æ˜**ï¼šç”¨ä»£ç ç¤ºä¾‹è§£é‡Šæ¦‚å¿µ
3. **å¯¹æ¯”åˆ†æ**ï¼šè¯´æ˜ä¸åŒæ–¹æ¡ˆçš„ä¼˜ç¼ºç‚¹
4. **è¿½é—®å‡†å¤‡**ï¼šé¢„æµ‹é¢è¯•å®˜å¯èƒ½çš„è¿½é—®
5. **è¿æ¥åç»­**ï¼šæåŠä¸åç»­ milestone çš„å…³ç³»

---

**éœ€è¦æ›´æ·±å…¥çš„è®¨è®ºï¼Ÿ** æŸ¥çœ‹ [å­¦ä¹ ç¬”è®°](../learn/milestone_0.md) äº†è§£æŠ€æœ¯åŸç†ã€‚

