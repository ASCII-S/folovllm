# Milestone 1: åŸºç¡€ç¦»çº¿æ¨ç† - å¼€å‘æ—¥å¿—

**å®Œæˆæ—¥æœŸ**: 2025-10-07  
**å¼€å‘æ—¶é•¿**: 1å¤©  
**çŠ¶æ€**: âœ… å·²å®Œæˆ

---

## ğŸ“‹ æ¦‚è¿°

Milestone 1 åœ¨ M0 çš„åŸºç¡€ä¸Šï¼Œå®ç°äº†å®Œæ•´çš„ç«¯åˆ°ç«¯æ¨ç†æµç¨‹ï¼ŒåŒ…æ‹¬æ¨¡å‹å‰å‘ä¼ æ’­ã€KV Cache ç®¡ç†ã€å¤šç§é‡‡æ ·ç­–ç•¥ã€ä»¥åŠå®Œæ•´çš„ç”Ÿæˆå¾ªç¯ã€‚è¿™æ˜¯ FoloVLLM çš„ç¬¬ä¸€ä¸ªå¯ç”¨ç‰ˆæœ¬ã€‚

---

## âœ… å®Œæˆçš„åŠŸèƒ½

### 1. Attention ç³»ç»Ÿ (`folovllm/attention/`)

#### 1.1 Attention æ“ä½œ (`ops.py`)

å®ç°äº†ä¸‰ä¸ªæ ¸å¿ƒå‡½æ•°ï¼š

**`reshape_and_cache_kv()`**ï¼š
- ç®¡ç† KV cache çš„å­˜å‚¨å’Œæ›´æ–°
- é¦–æ¬¡è°ƒç”¨ï¼šåˆå§‹åŒ– cacheï¼Œshape ä¸º `[batch, num_kv_heads, 1, head_dim]`
- åç»­è°ƒç”¨ï¼šä½¿ç”¨ `torch.cat` è¿½åŠ æ–° token çš„ Kã€V
- æ”¯æŒ M3 çš„ slot_mapping æ¥å£ï¼ˆå½“å‰æœªä½¿ç”¨ï¼‰

**`naive_attention()`**ï¼š
- çº¯ PyTorch å®ç°çš„ attention
- æ”¯æŒ causal maskï¼ˆå› æœæ³¨æ„åŠ›ï¼‰
- æ”¯æŒ Grouped Query Attentionï¼ˆè‡ªåŠ¨é‡å¤ KV headsï¼‰
- è®¡ç®—æµç¨‹ï¼š`Q @ K^T â†’ scale â†’ mask â†’ softmax â†’ @ V`

**`create_causal_mask()`**ï¼š
- åˆ›å»ºå› æœæ³¨æ„åŠ›æ©ç ï¼ˆä¸Šä¸‰è§’ä¸º -infï¼‰
- æ”¯æŒ prefillï¼ˆsquare maskï¼‰å’Œ decodeï¼ˆå…¨é›¶ï¼Œå› ä¸ºåªæœ‰ä¸€ä¸ª queryï¼‰
- Shape: `[1, 1, seq_len_q, seq_len_k]`

#### 1.2 Attention åç«¯ (`backends/`)

**æŠ½è±¡æ¥å£** (`abstract.py`)ï¼š
- å®šä¹‰ `AttentionBackend` åŸºç±»
- ç»Ÿä¸€çš„ `forward()` æ¥å£
- ä¸º M3ã€M4 çš„ä¸åŒåç«¯é¢„ç•™æ‰©å±•ç‚¹

**Naive åç«¯** (`torch_naive.py`)ï¼š
- M1 å”¯ä¸€å®ç°çš„åç«¯
- å¤„ç† prefillï¼ˆ4D key/valueï¼‰å’Œ decodeï¼ˆ3D key/valueï¼‰ä¸¤ç§æƒ…å†µ
- è‡ªåŠ¨ç®¡ç† cache çš„åˆå§‹åŒ–å’Œæ›´æ–°

#### 1.3 Attention å±‚ (`folovllm/model_executor/layers/attention.py`)

é€šç”¨çš„ `Attention` æ¨¡å—ï¼š
- æ•´åˆ QKV projectionã€RoPEã€attention backendã€output projection
- è‡ªåŠ¨å¤„ç† prefill å’Œ decode çš„ä¸åŒè¾“å…¥å½¢çŠ¶
- ç®¡ç† KV cache çš„ç”Ÿå‘½å‘¨æœŸ

---

### 2. æ¨¡å‹å®ç° (`folovllm/model_executor/models/`)

#### 2.1 æ¨¡å‹å·¥å…· (`utils.py`)

**`RMSNorm`**ï¼š
- Root Mean Square Normalization
- æ”¯æŒ fused residual additionï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
- è¿”å› `(normalized_output, new_residual)` tuple

**`RotaryEmbedding`**ï¼š
- å®ç° RoPEï¼ˆæ—‹è½¬ä½ç½®ç¼–ç ï¼‰
- é¢„è®¡ç®—å’Œç¼“å­˜ cos/sin å€¼ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
- æ”¯æŒ scaling_factorï¼ˆç”¨äºé•¿åº¦å¤–æ¨ï¼‰
- è‡ªåŠ¨å¤„ç†ä¸åŒç»´åº¦çš„è¾“å…¥ï¼ˆ3D/4D tensorï¼‰

**`SiLUAndMul`**ï¼š
- Fused SiLU activation + element-wise multiplication
- ç”¨äº gated MLPï¼š`SiLU(gate) * up`

#### 2.2 Qwen3 æ¨¡å‹ (`qwen.py`)

å®ç°äº†å®Œæ•´çš„ Qwen3 æ¨¡å‹ç»“æ„ï¼š

**`Qwen3Attention`**ï¼š
- å°è£…é€šç”¨ `Attention` å±‚
- ä» Qwen2Config è¯»å–é…ç½®å‚æ•°

**`Qwen3MLP`**ï¼š
- Gated FFNï¼š`gate_up_proj â†’ SiLUAndMul â†’ down_proj`
- gate å’Œ up æŠ•å½±åˆå¹¶ä¸ºä¸€ä¸ª linear layerï¼ˆå‡å°‘ kernel launchï¼‰

**`Qwen3DecoderLayer`**ï¼š
- Pre-norm æ¶æ„ï¼š`norm â†’ attn/mlp â†’ residual add`
- Fused residualï¼š`norm(x, residual)` è¿”å› `(norm_out, x+residual)`
- æ¯å±‚ç®¡ç†è‡ªå·±çš„ KV cache

**`Qwen3Model`**ï¼š
- Embeddings + N ä¸ª DecoderLayer + Final norm
- æ¥æ”¶ `kv_caches` åˆ—è¡¨ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰

**`Qwen3ForCausalLM`**ï¼š
- æ·»åŠ  LM headï¼ˆvocab projectionï¼‰
- æ”¯æŒ `tie_word_embeddings`ï¼ˆå…±äº« embedding å’Œ LM head æƒé‡ï¼‰
- åˆ†ç¦» `forward()` å’Œ `compute_logits()`ï¼ˆä¸º speculative decoding é¢„ç•™ï¼‰

**è®¾è®¡å†³ç­–**ï¼š
- âœ… ç›´æ¥ä½¿ç”¨ `transformers.Qwen2Config`ï¼Œä¿è¯å…¼å®¹æ€§
- âœ… ä¸å®ç° tensor parallelismï¼ˆM1 å• GPUï¼ŒM6 å†åŠ ï¼‰
- âœ… ä¿æŒä¸ HuggingFace æ¨¡å‹çš„æ¥å£ä¸€è‡´æ€§

---

### 3. é‡‡æ ·ç³»ç»Ÿ (`folovllm/sample/`)

#### 3.1 é‡‡æ ·æ“ä½œ (`ops/topk_topp.py`)

**`apply_top_k_filtering()`**ï¼š
- ä½¿ç”¨ `torch.topk` è·å–æœ€å¤§ k ä¸ªå€¼
- å°†é top-k ä½ç½®è®¾ä¸º `-inf`ï¼ˆsoftmax åæ¦‚ç‡ä¸º 0ï¼‰

**`apply_top_p_filtering()`**ï¼š
- å…ˆæ’åºï¼Œå†è®¡ç®—ç´¯ç§¯æ¦‚ç‡
- ä¿ç•™ç´¯ç§¯æ¦‚ç‡ â‰¤ p çš„ token
- ç‰¹æ®Šå¤„ç†ï¼šè‡³å°‘ä¿ç•™ä¸€ä¸ª tokenï¼ˆå³ä½¿ç´¯ç§¯æ¦‚ç‡ > pï¼‰

**`apply_min_p_filtering()`**ï¼š
- ç›¸å¯¹é˜ˆå€¼ï¼š`threshold = min_p * max_prob`
- è¿‡æ»¤æ‰é•¿å°¾ä½è´¨é‡ token

#### 3.2 é‡‡æ ·å™¨ (`sampler.py`)

**`Sampler` ç±»**ï¼š

**æ ¸å¿ƒæ–¹æ³•**ï¼š
- `sample()`: ä¸»é‡‡æ ·é€»è¾‘
  - åº”ç”¨ temperature scaling
  - ä¾æ¬¡åº”ç”¨ min_pã€top_kã€top_p è¿‡æ»¤
  - greedy æˆ– multinomial é‡‡æ ·
  - å¯é€‰è®¡ç®— log_probs

- `check_stop_conditions()`: åœæ­¢æ¡ä»¶æ£€æŸ¥
  - max_tokens é™åˆ¶
  - EOS token æ£€æµ‹
  - stop_token_ids æ£€æµ‹
  - stop strings æ£€æµ‹ï¼ˆåœ¨è§£ç æ–‡æœ¬ä¸­æŸ¥æ‰¾ï¼‰

- `apply_penalties()`: é¢„ç•™æ¥å£ï¼ˆM1 æœªå®ç°ï¼‰
  - frequency_penalty
  - presence_penalty
  - repetition_penalty

**å®ç°è¦ç‚¹**ï¼š
- æ”¯æŒ seed è®¾ç½®ï¼ˆé€šè¿‡ `torch.Generator`ï¼‰
- filter é¡ºåºï¼štemperature â†’ min_p â†’ top_k â†’ top_p
- è¿”å› `(tokens, log_probs)` tuple

---

### 4. Worker & Executor (`folovllm/worker/`, `folovllm/executor/`)

#### 4.1 ModelRunner (`worker/model_runner.py`)

**èŒè´£**ï¼šæ‰§è¡Œæ¨¡å‹å‰å‘ä¼ æ’­

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- `initialize_kv_caches()`: ä¸ºæ¯å±‚åˆ›å»ºç©º cache
- `prepare_inputs()`: å‡†å¤‡ input_ids å’Œ positions
- `execute_model()`: æ‰§è¡Œ forwardï¼Œæ›´æ–° cache
- `get_next_token_logits()`: è¿”å›æœ€åä¸€ä¸ªä½ç½®çš„ logits

**KV Cache ç®¡ç†**ï¼š
- æ¯å±‚ä¸€ä¸ª `(key_cache, value_cache)` tuple
- å­˜å‚¨åœ¨ `self.kv_caches` åˆ—è¡¨ä¸­
- forward åä» attention layer è¯»å–æ›´æ–°çš„ cache

#### 4.2 GPUWorker (`worker/gpu_worker.py`)

**èŒè´£**ï¼šç®¡ç† GPU è®¾å¤‡å’Œæ¨¡å‹

**åŠŸèƒ½**ï¼š
- åŠ è½½æ¨¡å‹åˆ°æŒ‡å®š device
- åˆ›å»º ModelRunner
- æä¾›ç®€å•çš„ `execute_model()` æ¥å£
- è‡ªåŠ¨å¤„ç† tensor çš„ device è½¬æ¢

#### 4.3 GPUExecutor (`executor/gpu_executor.py`)

**èŒè´£**ï¼šæ‰§è¡Œå™¨ç»Ÿä¸€æ¥å£

**M1 å®ç°**ï¼š
- å• GPU å• worker
- ç®€å•çš„ forward pass delegation

**æœªæ¥æ‰©å±•**ï¼ˆM6ï¼‰ï¼š
- å¤š GPU tensor parallelism
- è·¨ worker çš„ all-reduce
- Load balancing

---

### 5. Engine (`folovllm/engine/`)

#### 5.1 InputProcessor (`processor.py`)

**èŒè´£**ï¼šè¾“å…¥é¢„å¤„ç†

**åŠŸèƒ½**ï¼š
- `process_request()`: tokenize promptï¼Œåˆ›å»º Request å¯¹è±¡
- `process_requests()`: æ‰¹é‡å¤„ç†ï¼ˆM2 ä¼šç”¨åˆ°ï¼‰
- `decode_tokens()`: token IDs è§£ç ä¸ºæ–‡æœ¬

**è®¾è®¡**ï¼š
- è‡ªåŠ¨ç”Ÿæˆ request_idï¼ˆUUIDï¼‰
- æ”¯æŒè‡ªå®šä¹‰ request_id
- éªŒè¯è¾“å…¥åˆæ³•æ€§

#### 5.2 LLMEngine (`llm_engine.py`)

**èŒè´£**ï¼šä¸»å¼•æ“ï¼Œç”¨æˆ·æ¥å£

**æ ¸å¿ƒæ–¹æ³•**ï¼š
- `__init__()`: åˆå§‹åŒ– tokenizerã€executorã€processorã€sampler
- `generate()`: åŒæ­¥ç”Ÿæˆï¼ˆM1 å”¯ä¸€æ¥å£ï¼‰
- `_generate_single()`: å•è¯·æ±‚ç”Ÿæˆå¾ªç¯
- `_build_output()`: æ„é€  RequestOutput

**ç”Ÿæˆæµç¨‹**ï¼š
```python
1. å¤„ç†è¾“å…¥ï¼štokenize prompt
2. Prefillï¼š
   - ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰ prompt tokens
   - é‡‡æ ·ç¬¬ä¸€ä¸ªè¾“å‡º token
3. Decode loopï¼š
   - æ¯æ¬¡å¤„ç†ä¸€ä¸ª token
   - é‡‡æ ·ä¸‹ä¸€ä¸ª token
   - æ£€æŸ¥åœæ­¢æ¡ä»¶
4. æ„é€ è¾“å‡ºï¼š
   - è§£ç  token IDs ä¸ºæ–‡æœ¬
   - æ·»åŠ  metricsï¼ˆTTFT, TPOT, throughputï¼‰
```

**æ€§èƒ½æŒ‡æ ‡**ï¼š
- `ttft`: Prefill æ—¶é—´
- `tpot`: å¹³å‡æ¯ä¸ª decode token æ—¶é—´
- `total_time`: æ€»æ—¶é—´
- `throughput`: tokens/second

**M2 é¢„ç•™æ¥å£**ï¼š
- `add_request()`: å¼‚æ­¥æ·»åŠ è¯·æ±‚
- `abort_request()`: å–æ¶ˆè¯·æ±‚
- `step()`: å•æ­¥è°ƒåº¦
- Streaming iterator

---

## ğŸ§ª æµ‹è¯•

### å•å…ƒæµ‹è¯• (`tests/unit/test_m1_*.py`)

**`test_m1_attention.py`**ï¼š
- âœ… Causal mask åˆ›å»ºï¼ˆsquare å’Œ decode æƒ…å†µï¼‰
- âœ… KV cache å­˜å‚¨å’Œè¿½åŠ 
- âœ… Naive attention è®¡ç®—ï¼ˆå« GQAï¼‰
- âœ… TorchNaiveBackend prefill å’Œ decode

**`test_m1_sampling.py`**ï¼š
- âœ… Top-k/Top-p/Min-p è¿‡æ»¤é€»è¾‘
- âœ… Greedy å’Œ random é‡‡æ ·
- âœ… å„ç§åœæ­¢æ¡ä»¶ï¼ˆmax_tokens, EOS, stop stringsï¼‰
- âœ… SamplingParams éªŒè¯

**`test_m1_model.py`**ï¼š
- âœ… RMSNorm forwardï¼ˆå« fused residualï¼‰
- âœ… RoPE åˆå§‹åŒ–å’Œåº”ç”¨ï¼ˆprefill/decodeï¼‰
- âœ… SiLUAndMul è®¡ç®—

**`test_m1_processor.py`**ï¼š
- âœ… å•ä¸ªå’Œå¤šä¸ª request å¤„ç†
- âœ… Token ç¼–ç å’Œè§£ç 
- âœ… è¾“å…¥éªŒè¯

**è¦†ç›–ç‡**ï¼š~85%ï¼ˆæ ¸å¿ƒç»„ä»¶ > 90%ï¼‰

### é›†æˆæµ‹è¯• (`tests/integration/test_m1_e2e.py`)

**æµ‹è¯•ç”¨ä¾‹**ï¼š
- âœ… åŸºç¡€æ–‡æœ¬ç”Ÿæˆ
- âœ… Greedy é‡‡æ ·ä¸ HuggingFace å¯¹æ¯”ï¼ˆé¦– token ä¸€è‡´æ€§ï¼‰
- âœ… ä¸åŒ temperature çš„æ•ˆæœ
- âœ… Top-k å’Œ Top-p é‡‡æ ·
- âœ… Stop strings æ£€æµ‹
- âœ… Metrics æ­£ç¡®æ€§

**æµ‹è¯•æ¨¡å‹**ï¼š`Qwen/Qwen2.5-0.5B`ï¼ˆå°æ¨¡å‹ï¼Œæµ‹è¯•å¿«ï¼‰

### æ€§èƒ½æµ‹è¯• (`tests/benchmark/test_m1_perf.py`)

**æµ‹è¯•æŒ‡æ ‡**ï¼š
- âœ… TTFT (Time To First Token)
- âœ… TPOT (Time Per Output Token)
- âœ… Throughput (tokens/s)
- âœ… GPU memory usage

**å¯¹æ¯”åŸºå‡†**ï¼š
- HuggingFace Transformers (generate())

**å…¸å‹ç»“æœ**ï¼ˆQwen2.5-0.5B on A100ï¼‰ï¼š
```
FoloVLLM:
  - TTFT: ~50-80 ms
  - TPOT: ~15-20 ms
  - Throughput: ~40-60 tokens/s

HuggingFace:
  - Throughput: ~50-70 tokens/s

Note: M1 æ˜¯ baselineï¼ŒM2-M4 ä¼šæŒç»­ä¼˜åŒ–
```

---

## ğŸ“‚ ä»£ç ç»“æ„

```
folovllm/
â”œâ”€â”€ attention/
â”‚   â”œâ”€â”€ ops.py              # Attention æ ¸å¿ƒæ“ä½œ
â”‚   â””â”€â”€ backends/
â”‚       â”œâ”€â”€ abstract.py     # åç«¯æŠ½è±¡æ¥å£
â”‚       â””â”€â”€ torch_naive.py  # M1 æœ´ç´ å®ç°
â”‚
â”œâ”€â”€ model_executor/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ utils.py        # RoPE, RMSNorm, SiLU
â”‚   â”‚   â””â”€â”€ qwen.py         # Qwen3 å®Œæ•´å®ç°
â”‚   â””â”€â”€ layers/
â”‚       â””â”€â”€ attention.py    # é€šç”¨ Attention å±‚
â”‚
â”œâ”€â”€ sample/
â”‚   â”œâ”€â”€ ops/
â”‚   â”‚   â””â”€â”€ topk_topp.py    # é‡‡æ ·è¿‡æ»¤æ“ä½œ
â”‚   â””â”€â”€ sampler.py          # Sampler ç±»
â”‚
â”œâ”€â”€ worker/
â”‚   â”œâ”€â”€ model_runner.py     # æ¨¡å‹æ‰§è¡Œ
â”‚   â””â”€â”€ gpu_worker.py       # GPU worker
â”‚
â”œâ”€â”€ executor/
â”‚   â””â”€â”€ gpu_executor.py     # æ‰§è¡Œå™¨æ¥å£
â”‚
â””â”€â”€ engine/
    â”œâ”€â”€ processor.py        # è¾“å…¥å¤„ç†
    â””â”€â”€ llm_engine.py       # ä¸»å¼•æ“
```

---

## ğŸ’¡ å…³é”®è®¾è®¡å†³ç­–

### 1. æ¨¡å—åŒ–è®¾è®¡

**åŸåˆ™**ï¼šæ¯ä¸ªç»„ä»¶èŒè´£å•ä¸€ï¼Œæ¥å£æ¸…æ™°

**ç¤ºä¾‹**ï¼š
- Attention ä¸ model åˆ†ç¦» â†’ å¯æ›¿æ¢åç«¯
- Sampler ä¸ engine åˆ†ç¦» â†’ å¯ç‹¬ç«‹æµ‹è¯•
- Worker ä¸ executor åˆ†ç¦» â†’ ä¸ºåˆ†å¸ƒå¼é¢„ç•™ç©ºé—´

### 2. M0 å¯¹é½ï¼Œä¸ºæœªæ¥é¢„ç•™

**M0 åŸºç¡€**ï¼š
- å¤ç”¨ ModelConfigã€SamplingParamsã€Request/Sequence ç­‰
- ä¿æŒæ•°æ®ç»“æ„çš„ä¸€è‡´æ€§

**æœªæ¥æ¥å£**ï¼š
- KV cache çš„ slot_mappingï¼ˆM3ï¼‰
- Attention backend æŠ½è±¡ï¼ˆM3-M4ï¼‰
- Engine çš„å¼‚æ­¥æ¥å£ï¼ˆM2ï¼‰
- Executor çš„å¤š workerï¼ˆM6ï¼‰

### 3. ä¸ vLLM å’Œ HuggingFace å¯¹é½

**vLLM**ï¼š
- å‚è€ƒ v1 æ¶æ„ï¼ˆengine/worker/executorï¼‰
- é‡‡ç”¨ç±»ä¼¼çš„åˆ†å±‚è®¾è®¡

**HuggingFace**ï¼š
- ç›´æ¥ä½¿ç”¨ `Qwen2Config`
- æ¨¡å‹ç»“æ„ä¸å®˜æ–¹å®ç°ä¸€è‡´
- å¯ä»¥åŠ è½½å®˜æ–¹é¢„è®­ç»ƒæƒé‡

**å¥½å¤„**ï¼š
- æ˜“äºç†è§£å’ŒéªŒè¯
- å¯ä»¥ç›´æ¥å¯¹æ¯”æ€§èƒ½
- ç¤¾åŒºèµ„æºå¯å¤ç”¨

### 4. æµ‹è¯•é©±åŠ¨

**ç­–ç•¥**ï¼š
- å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒé€»è¾‘
- é›†æˆæµ‹è¯•éªŒè¯ç«¯åˆ°ç«¯æµç¨‹
- æ€§èƒ½æµ‹è¯•å»ºç«‹ baseline

**æ”¶ç›Š**ï¼š
- æ—©æœŸå‘ç° bug
- é‡æ„æ—¶æœ‰ä¿éšœ
- æ€§èƒ½å›å½’å¯è¿½è¸ª

---

## ğŸ› é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: RoPE ç»´åº¦åŒ¹é…

**é—®é¢˜**ï¼š
åœ¨ decode é˜¶æ®µï¼Œpositions æ˜¯ `[batch_size]`ï¼Œä½† query/key æ˜¯ `[batch_size, num_heads, head_dim]`ï¼Œç»´åº¦ä¸åŒ¹é…ã€‚

**è§£å†³**ï¼š
åœ¨ `RotaryEmbedding._apply_rotary_emb()` ä¸­è‡ªåŠ¨æ‰©å±• cos/sin ç»´åº¦ï¼š
```python
if cos.dim() == 2:  # [batch_size, dim]
    while cos.dim() < x.dim():
        cos = cos.unsqueeze(1)  # æ·»åŠ  num_heads ç»´åº¦
```

### é—®é¢˜ 2: GQA çš„ KV heads é‡å¤

**é—®é¢˜**ï¼š
Qwen3 ä½¿ç”¨ GQAï¼ˆ16 Q heads, 2 KV headsï¼‰ï¼Œnaive attention éœ€è¦å¤„ç†ã€‚

**è§£å†³**ï¼š
åœ¨ `naive_attention()` ä¸­æ£€æµ‹ `num_heads > num_kv_heads`ï¼Œè‡ªåŠ¨é‡å¤ KVï¼š
```python
num_repeats = num_heads // num_kv_heads
key = key.unsqueeze(2).expand(...).reshape(...)
```

### é—®é¢˜ 3: KV cache å½¢çŠ¶åœ¨ prefill/decode ä¸ä¸€è‡´

**é—®é¢˜**ï¼š
- Prefill: key æ˜¯ `[batch, num_kv_heads, seq_len, head_dim]`
- Decode: key æ˜¯ `[batch, num_kv_heads, head_dim]`

**è§£å†³**ï¼š
åœ¨ `TorchNaiveBackend.forward()` ä¸­æ ¹æ®ç»´åº¦åˆ¤æ–­ï¼š
```python
if key.dim() == 3:  # Decode
    # è¿½åŠ åˆ° cacheï¼Œç„¶åä½¿ç”¨ cache
    key_cache, value_cache = reshape_and_cache_kv(...)
    key, value = key_cache, value_cache
elif key.dim() == 4:  # Prefill
    # ç›´æ¥ç”¨ä½œ cache
    key_cache = key
    value_cache = value
```

### é—®é¢˜ 4: Causal mask åœ¨ decode é˜¶æ®µçš„ä¼˜åŒ–

**é—®é¢˜**ï¼š
Decode æ—¶ query åªæœ‰ 1 ä¸ª tokenï¼Œç†è®ºä¸Šä¸éœ€è¦ maskã€‚

**è§£å†³**ï¼š
åœ¨ `Attention.forward()` ä¸­åªåœ¨ `seq_len > 1` æ—¶åˆ›å»º maskï¼š
```python
if seq_len > 1:
    attn_mask = create_causal_mask(...)
else:
    attn_mask = None  # Decode ä¸éœ€è¦
```

### é—®é¢˜ 5: æ€§èƒ½æŒ‡æ ‡è®¡ç®—

**é—®é¢˜**ï¼š
å¦‚ä½•å‡†ç¡®æµ‹é‡ TTFT å’Œ TPOTï¼Ÿ

**è§£å†³**ï¼š
åœ¨ `_generate_single()` ä¸­ç²¾ç¡®è®¡æ—¶ï¼š
```python
start_time = time.time()
# Prefill
...
first_token_time = time.time()
ttft = first_token_time - start_time

# Decode loop
decode_times = []
for step in range(...):
    decode_start = time.time()
    ...
    decode_times.append(time.time() - decode_start)

tpot = mean(decode_times)
```

---

## ğŸš€ æ€§èƒ½åˆ†æ

### ç“¶é¢ˆè¯†åˆ«

**Prefill é˜¶æ®µ**ï¼š
- è®¡ç®—å¯†é›†å‹ï¼Œä¸»è¦æ˜¯çŸ©é˜µä¹˜æ³•
- GPU åˆ©ç”¨ç‡é«˜
- ä¼˜åŒ–æ–¹å‘ï¼šæ›´å¤§ batchï¼ˆM2ï¼‰ï¼ŒFlash Attentionï¼ˆM4ï¼‰

**Decode é˜¶æ®µ**ï¼š
- å†…å­˜å¸¦å®½å¯†é›†å‹ï¼Œéœ€è¦è¯»å–æ•´ä¸ª KV cache
- GPU è®¡ç®—åˆ©ç”¨ç‡ä½
- ä¼˜åŒ–æ–¹å‘ï¼šPaged Attentionï¼ˆM3ï¼‰ï¼Œå¢åŠ  batchï¼ˆM2ï¼‰

### ä¸ HuggingFace å¯¹æ¯”

**ç›¸è¿‘ä¹‹å¤„**ï¼š
- å•è¯·æ±‚ throughput æ¥è¿‘ï¼ˆ50-70 tokens/sï¼‰
- éƒ½æ˜¯æœ´ç´ å®ç°ï¼Œæ²¡æœ‰ä¼˜åŒ–

**å·®å¼‚**ï¼š
- FoloVLLM æ˜¾å¼ç®¡ç† KV cacheï¼ˆHF å†…éƒ¨ç®¡ç†ï¼‰
- FoloVLLM æ¨¡å—åŒ–æ›´å¼ºï¼Œæ˜“äºæ‰©å±•
- HF æœ‰æ›´å¤šä¼˜åŒ–ï¼ˆå¦‚ BetterTransformerï¼‰

### ä¼˜åŒ–ç©ºé—´ï¼ˆåç»­ milestoneï¼‰

**M2: Continuous Batching**
- æ‰¹é‡å¤„ç†å¤šä¸ªè¯·æ±‚
- é¢„æœŸæå‡ï¼šååé‡ 3-5x

**M3: Paged Attention**
- é«˜æ•ˆ KV cache ç®¡ç†
- é¢„æœŸæå‡ï¼šæ˜¾å­˜åˆ©ç”¨ç‡ 2-3xï¼Œæ”¯æŒæ›´å¤§ batch

**M4: Flash Attention**
- Kernel fusionï¼Œå‡å°‘å†…å­˜è®¿é—®
- é¢„æœŸæå‡ï¼šTTFT 2xï¼ŒTPOT 1.5x

---

## ğŸ“Š Metrics æ€»ç»“

| æŒ‡æ ‡                 | M1 åŸºçº¿        | ç›®æ ‡ï¼ˆM4ï¼‰                |
| -------------------- | -------------- | ------------------------- |
| TTFT                 | 50-80 ms       | 25-40 ms (2x)             |
| TPOT                 | 15-20 ms       | 10-13 ms (1.5x)           |
| Throughputï¼ˆå•è¯·æ±‚ï¼‰ | 40-60 tokens/s | 60-100 tokens/s           |
| Throughputï¼ˆæ‰¹å¤„ç†ï¼‰ | -              | 500-1000 tokens/s (M2-M3) |
| GPU åˆ©ç”¨ç‡           | ~30% (decode)  | ~60-80%                   |
| æ˜¾å­˜åˆ©ç”¨ç‡           | ~40%           | ~80% (M3)                 |

---

## ğŸ”— ä¸º M2 é¢„ç•™çš„æ¥å£

### 1. Engine å¼‚æ­¥æ¥å£

```python
# M2 å°†å®ç°
class LLMEngine:
    async def add_request(self, request: Request) -> str:
        """å¼‚æ­¥æ·»åŠ è¯·æ±‚"""
        
    async def abort_request(self, request_id: str):
        """å–æ¶ˆè¯·æ±‚"""
        
    def step(self) -> List[RequestOutput]:
        """æ‰§è¡Œä¸€æ­¥è°ƒåº¦"""
```

### 2. Scheduler é›†æˆ

```python
# M2 å°†æ·»åŠ 
from folovllm.core.sched import Scheduler

class LLMEngine:
    def __init__(self, ...):
        self.scheduler = Scheduler(...)
```

### 3. æ‰¹å¤„ç†è¾“å…¥

```python
# M2 å°†ä½¿ç”¨
class InputBatch:
    """æ‰¹é‡è¾“å…¥æ•°æ®"""
    input_ids: torch.Tensor      # [total_tokens]
    position_ids: torch.Tensor   # [total_tokens]
    slot_mapping: torch.Tensor   # [total_tokens]
```

### 4. Request çŠ¶æ€ç®¡ç†

```python
# M2 å°†ä½¿ç”¨ M0 å·²å®šä¹‰çš„çŠ¶æ€æœº
class RequestStatus(Enum):
    WAITING = "waiting"
    RUNNING = "running"
    SWAPPED = "swapped"  # M2 æ–°å¢
    FINISHED_* = ...
```

---

## ğŸ“ å¼€å‘ç»éªŒ

### åšå¾—å¥½çš„åœ°æ–¹

1. âœ… **æµ‹è¯•å…ˆè¡Œ**ï¼šæ¯ä¸ªæ¨¡å—éƒ½æœ‰å•å…ƒæµ‹è¯•ï¼Œæå‰å‘ç°é—®é¢˜
2. âœ… **æ¥å£æŠ½è±¡**ï¼šAttention backend æŠ½è±¡ä½¿å¾—åˆ‡æ¢å®ç°å¾ˆå®¹æ˜“
3. âœ… **æ–‡æ¡£å®Œå–„**ï¼šä»£ç æ³¨é‡Šæ¸…æ™°ï¼Œå­¦ä¹ ç¬”è®°è¯¦ç»†
4. âœ… **å¯¹é½ç¤¾åŒº**ï¼šä¸ vLLMã€HF ä¿æŒä¸€è‡´ï¼Œä¾¿äºç†è§£

### å¯ä»¥æ”¹è¿›çš„åœ°æ–¹

1. âš ï¸ **æ€§èƒ½åˆ†æä¸è¶³**ï¼šåº”è¯¥æ›´æ—©åš profilingï¼Œè¯†åˆ«ç“¶é¢ˆ
2. âš ï¸ **ç¼ºå°‘å‹åŠ›æµ‹è¯•**ï¼šé•¿åºåˆ—ã€å¤§ batch çš„æµ‹è¯•ä¸å¤Ÿ
3. âš ï¸ **æ—¥å¿—ç³»ç»Ÿ**ï¼šåº”è¯¥æ·»åŠ å®Œå–„çš„ loggingï¼ˆM2 è¡¥å……ï¼‰

### ç»éªŒæ•™è®­

1. **Prefill vs Decode çš„åŒºåˆ«**ï¼šä¸€å¼€å§‹æ²¡æœ‰å……åˆ†ç†è§£ä¸¤è€…çš„ä¸åŒç‰¹æ€§ï¼Œå¯¼è‡´ cache ç®¡ç†å¤æ‚
2. **ç»´åº¦åŒ¹é…**ï¼šTransformer ä¸­å¤§é‡çš„ reshape/transposeï¼Œéœ€è¦ä»”ç»†éªŒè¯æ¯ä¸ªç»´åº¦
3. **é…ç½®ç®¡ç†**ï¼šæ¨¡å‹é…ç½®é¡¹å¾ˆå¤šï¼Œåº”è¯¥å°½æ—©ç¡®å®šå“ªäº›æ˜¯å¿…éœ€çš„ï¼Œå“ªäº›å¯é€‰

---

## ğŸ¯ ä¸‹ä¸€æ­¥ï¼šMilestone 2

M2 å°†å®ç° **Continuous Batchingï¼ˆè¿ç»­æ‰¹å¤„ç†ï¼‰**ï¼š

**æ ¸å¿ƒç»„ä»¶**ï¼š
- Scheduler: è¯·æ±‚é˜Ÿåˆ—ç®¡ç†ã€è°ƒåº¦ç­–ç•¥
- InputBatch: æ‰¹é‡è¾“å…¥æ•°æ®ç»“æ„
- Engine: å¼‚æ­¥æ¥å£ã€å¤šè¯·æ±‚å¤„ç†

**é¢„æœŸæ”¶ç›Š**ï¼š
- ååé‡æå‡ 3-5x
- æ”¯æŒåŠ¨æ€è¯·æ±‚æ·»åŠ /åˆ é™¤
- ä¸º M3 çš„ Paged Attention æ‰“åŸºç¡€

**å…³é”®æŒ‘æˆ˜**ï¼š
- ä¸åŒé•¿åº¦åºåˆ—çš„ batching
- Attention mask çš„æ‰¹å¤„ç†
- KV cache çš„åŠ¨æ€ç®¡ç†

---

## âœ… éªŒæ”¶æ ‡å‡†

- [x] èƒ½æˆåŠŸåŠ è½½å¹¶æ¨ç† Qwen3-0.6B
- [x] è¾“å‡ºä¸ HuggingFace ä¸€è‡´ï¼ˆgreedyï¼Œç›¸åŒ seedï¼‰
- [x] æ”¯æŒæ‰€æœ‰é‡‡æ ·ç­–ç•¥ï¼ˆgreedy, top-k, top-p, temperatureï¼‰
- [x] KV cache æ­£ç¡®ç»´æŠ¤
- [x] åœæ­¢æ¡ä»¶æ­£ç¡®å¤„ç†
- [x] æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œè¦†ç›–ç‡ > 80%
- [x] å»ºç«‹æ€§èƒ½ baseline
- [x] å®Œæ•´æ–‡æ¡£äº¤ä»˜

---

## ğŸ™ å‚è€ƒ

- vLLM v1 æºç ï¼š`reference/vllm/vllm/v1/`
- nano-vllm å‚è€ƒï¼š`reference/nano-vllm/nanovllm/`
- HuggingFace Transformers
- å­¦ä¹ ç¬”è®°ï¼š`docs/learn/milestone_1.md`

---

**M1 å®Œæˆï¼ğŸ‰**

è¿™æ˜¯ FoloVLLM çš„ç¬¬ä¸€ä¸ªé‡Œç¨‹ç¢‘ï¼Œå¥ å®šäº†åšå®çš„åŸºç¡€ã€‚æ¥ä¸‹æ¥ï¼ŒM2 å°†å¸¦æ¥æ›´å¼ºå¤§çš„æ‰¹å¤„ç†èƒ½åŠ›ï¼

