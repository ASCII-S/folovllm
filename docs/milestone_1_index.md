# Milestone 1: åŸºç¡€ç¦»çº¿æ¨ç† - æ–‡æ¡£ç´¢å¼•

**å®Œæˆæ—¥æœŸ**: 2025-10-07  
**çŠ¶æ€**: âœ… å·²å®Œæˆ

---

## ğŸ“– æ–‡æ¡£å¯¼èˆª

### æ ¸å¿ƒæ–‡æ¡£

1. **[å­¦ä¹ ç¬”è®°](learn/milestone_1.md)** â­ æ¨èé¦–è¯»
   - KV Cache åŸç†ä¸å®ç°
   - Transformer æ¨ç†æµç¨‹ï¼ˆPrefill vs Decodeï¼‰
   - Sampling ç­–ç•¥è¯¦è§£ï¼ˆGreedy, Top-k, Top-p, Temperatureï¼‰
   - RoPEï¼ˆæ—‹è½¬ä½ç½®ç¼–ç ï¼‰
   - RMSNorm ä¸ LayerNorm å¯¹æ¯”
   - GQAï¼ˆGrouped Query Attentionï¼‰
   - **7 ä¸ªé¢è¯•é—®é¢˜åŠè¯¦ç»†è§£ç­”**

2. **[å£è¿°å±•ç¤ºæ–‡æ¡£](presentation/milestone_1.md)** ğŸ¯ é€‚åˆå‘å°ç™½è®²è§£
   - ä»¥ç±»/å‡½æ•°ä¸ºå•ä½è¯¦ç»†è®²è§£å®ç°è¿‡ç¨‹
   - Attention ç³»ç»Ÿå®ç°ï¼ˆKV Cacheã€Naive Attentionã€Backendï¼‰
   - æ¨¡å‹å·¥å…·å®ç°ï¼ˆRMSNormã€RoPEã€SiLUï¼‰
   - Qwen3 æ¨¡å‹æ¶æ„è®²è§£
   - é‡‡æ ·ç³»ç»Ÿè¯¦è§£ï¼ˆTop-kã€Top-pã€Temperatureï¼‰
   - Worker å’Œ Executor æ¶æ„
   - Engine å®ç°ä¸å®Œæ•´æ¨ç†æµç¨‹ä¸²è®²

3. **[é¢è¯•æŒ‡å—](interview/milestone_1.md)** ğŸ“ é¢è¯•å‡†å¤‡å¿…è¯»
   - KV Cache ç›¸å…³ï¼ˆå†…å­˜è®¡ç®—ã€Prefill vs Decodeï¼‰
   - Attention æœºåˆ¶ï¼ˆScaleã€GQAã€Causal Maskï¼‰
   - ä½ç½®ç¼–ç ï¼ˆRoPE åŸç†ã€å¤–æ¨æ€§ï¼‰
   - é‡‡æ ·ç­–ç•¥ï¼ˆå„ç­–ç•¥å¯¹æ¯”ã€é¡ºåºåŸå› ã€å¯å¤ç°æ€§ï¼‰
   - æ¨¡å‹æ¶æ„ï¼ˆRMSNorm vs LayerNormã€SiLUã€åˆå¹¶æŠ•å½±ï¼‰
   - æ¨ç†ä¼˜åŒ–ï¼ˆç“¶é¢ˆåˆ†æã€Continuous Batchingã€å†…å­˜ä¼˜åŒ–ï¼‰
   - ç³»ç»Ÿè®¾è®¡ï¼ˆåˆ†å±‚æ¶æ„ã€HF vs è‡ªå®šä¹‰æ¨¡å‹ï¼‰
   - æ•°å€¼ç¨³å®šæ€§ï¼ˆFP16/FP32ã€Epsilonã€æ··åˆç²¾åº¦ï¼‰

4. **[å¼€å‘æ—¥å¿—](dev/milestone_1.md)**
   - å®Œæ•´åŠŸèƒ½æ¸…å•
   - ä»£ç ç»“æ„è¯´æ˜
   - å®ç°ç»†èŠ‚ä¸è®¾è®¡å†³ç­–
   - é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
   - æ€§èƒ½åˆ†æä¸ä¼˜åŒ–æ–¹å‘
   - ä¸º M2 é¢„ç•™çš„æ¥å£

5. **[å®Œæˆæ€»ç»“](dev/M1_COMPLETION_SUMMARY.md)**
   - äº¤ä»˜ç‰©æ¸…å•
   - åŠŸèƒ½éªŒè¯ç»“æœ
   - æµ‹è¯•è¦†ç›–æƒ…å†µ
   - ä½¿ç”¨ç¤ºä¾‹
   - éªŒæ”¶æ ‡å‡†æ£€æŸ¥

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…å’Œè¿è¡Œ

```bash
# 1. å®‰è£…ä¾èµ–ï¼ˆå¦‚æœè¿˜æ²¡å®‰è£…ï¼‰
pip install -r requirements.txt
pip install -e .

# 2. è¿è¡Œç¤ºä¾‹
python examples/m1_inference.py \
    --model Qwen/Qwen3-0.6B \
    --prompt "What is the capital of France?" \
    --max-tokens 50 \
    --temperature 0.0

# 3. è¿è¡Œæµ‹è¯•
pytest tests/unit/test_m1_*.py -v
pytest tests/integration/test_m1_e2e.py -v -s

# 4. æ€§èƒ½åŸºå‡†æµ‹è¯•
python tests/benchmark/test_m1_perf.py
```

### ä»£ç ç¤ºä¾‹

```python
from folovllm import LLMEngine, ModelConfig, SamplingParams

# åˆå§‹åŒ–å¼•æ“
config = ModelConfig(
    model="Qwen/Qwen3-0.6B",
    dtype="float16",
    trust_remote_code=True,
)
engine = LLMEngine(config, device="cuda")

# ç”Ÿæˆæ–‡æœ¬
params = SamplingParams(
    temperature=0.7,
    top_k=50,
    top_p=0.95,
    max_tokens=100,
)
output = engine.generate("Hello, world!", params)

print(output.outputs[0].text)
print(f"TTFT: {output.metrics['ttft']*1000:.2f} ms")
print(f"Throughput: {output.metrics['throughput']:.2f} tokens/s")
```

---

## ğŸ“‚ ä»£ç ç»„ç»‡

### æ ¸å¿ƒå®ç°

```
folovllm/
â”œâ”€â”€ attention/                    # Attention ç³»ç»Ÿ
â”‚   â”œâ”€â”€ ops.py                   # KV cache, naive attention
â”‚   â””â”€â”€ backends/
â”‚       â”œâ”€â”€ abstract.py          # Backend æŠ½è±¡
â”‚       â””â”€â”€ torch_naive.py       # Naive backend å®ç°
â”‚
â”œâ”€â”€ model_executor/              # æ¨¡å‹æ‰§è¡Œ
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ utils.py             # RoPE, RMSNorm, SiLU
â”‚   â”‚   â””â”€â”€ qwen.py              # Qwen3 å®Œæ•´å®ç°
â”‚   â””â”€â”€ layers/
â”‚       â””â”€â”€ attention.py         # é€šç”¨ Attention å±‚
â”‚
â”œâ”€â”€ sample/                      # é‡‡æ ·
â”‚   â”œâ”€â”€ ops/
â”‚   â”‚   â””â”€â”€ topk_topp.py         # Top-k/p/min-p æ“ä½œ
â”‚   â””â”€â”€ sampler.py               # å®Œæ•´é‡‡æ ·å™¨
â”‚
â”œâ”€â”€ worker/                      # Worker
â”‚   â”œâ”€â”€ model_runner.py          # æ¨¡å‹è¿è¡Œå™¨
â”‚   â””â”€â”€ gpu_worker.py            # GPU worker
â”‚
â”œâ”€â”€ executor/                    # æ‰§è¡Œå™¨
â”‚   â””â”€â”€ gpu_executor.py          # GPU executor
â”‚
â””â”€â”€ engine/                      # å¼•æ“
    â”œâ”€â”€ processor.py             # è¾“å…¥å¤„ç†å™¨
    â””â”€â”€ llm_engine.py            # LLM å¼•æ“
```

### æµ‹è¯•

```
tests/
â”œâ”€â”€ unit/                        # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_m1_attention.py    # Attention æµ‹è¯•
â”‚   â”œâ”€â”€ test_m1_sampling.py     # Sampling æµ‹è¯•
â”‚   â”œâ”€â”€ test_m1_model.py        # æ¨¡å‹ç»„ä»¶æµ‹è¯•
â”‚   â””â”€â”€ test_m1_processor.py    # Processor æµ‹è¯•
â”‚
â”œâ”€â”€ integration/                 # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ test_m1_e2e.py          # ç«¯åˆ°ç«¯æµ‹è¯•
â”‚
â””â”€â”€ benchmark/                   # æ€§èƒ½æµ‹è¯•
    â””â”€â”€ test_m1_perf.py         # æ€§èƒ½åŸºå‡†
```

### ç¤ºä¾‹å’Œæ–‡æ¡£

```
examples/
â””â”€â”€ m1_inference.py              # CLI æ¨ç†ç¤ºä¾‹

docs/
â”œâ”€â”€ learn/
â”‚   â””â”€â”€ milestone_1.md           # å­¦ä¹ ç¬”è®°
â”œâ”€â”€ presentation/
â”‚   â””â”€â”€ milestone_1.md           # å£è¿°å±•ç¤ºæ–‡æ¡£
â”œâ”€â”€ interview/
â”‚   â””â”€â”€ milestone_1.md           # é¢è¯•æŒ‡å—
â”œâ”€â”€ dev/
â”‚   â”œâ”€â”€ milestone_1.md           # å¼€å‘æ—¥å¿—
â”‚   â””â”€â”€ M1_COMPLETION_SUMMARY.md # å®Œæˆæ€»ç»“
â””â”€â”€ milestone_1_index.md         # æœ¬æ–‡æ¡£
```

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### å·²å®ç°åŠŸèƒ½

| åŠŸèƒ½                    | æè¿°                              | æ–‡ä»¶                             |
| ----------------------- | --------------------------------- | -------------------------------- |
| **KV Cache**            | è¿ç»­å†…å­˜åˆ†é…ï¼Œæ”¯æŒ prefill/decode | `attention/ops.py`               |
| **Naive Attention**     | æœ´ç´  attention å®ç°ï¼Œæ”¯æŒ GQA     | `attention/ops.py`               |
| **RoPE**                | æ—‹è½¬ä½ç½®ç¼–ç                       | `model_executor/models/utils.py` |
| **RMSNorm**             | Root Mean Square å½’ä¸€åŒ–           | `model_executor/models/utils.py` |
| **Qwen3 Model**         | å®Œæ•´ Qwen3 æ¨¡å‹å®ç°               | `model_executor/models/qwen.py`  |
| **Greedy Sampling**     | è´ªå¿ƒé‡‡æ ·ï¼ˆtemperature=0ï¼‰         | `sample/sampler.py`              |
| **Top-k Sampling**      | Top-k è¿‡æ»¤é‡‡æ ·                    | `sample/sampler.py`              |
| **Top-p Sampling**      | Nucleusï¼ˆæ ¸é‡‡æ ·ï¼‰                 | `sample/sampler.py`              |
| **Temperature**         | æ¸©åº¦ç¼©æ”¾                          | `sample/sampler.py`              |
| **Stop Conditions**     | åœæ­¢æ¡ä»¶æ£€æµ‹                      | `sample/sampler.py`              |
| **LLM Engine**          | å®Œæ•´æ¨ç†å¼•æ“                      | `engine/llm_engine.py`           |
| **Performance Metrics** | TTFT, TPOT, throughput            | `engine/llm_engine.py`           |

### æµ‹è¯•è¦†ç›–

- âœ… å•å…ƒæµ‹è¯•ï¼š85% è¦†ç›–ç‡
- âœ… é›†æˆæµ‹è¯•ï¼šç«¯åˆ°ç«¯éªŒè¯
- âœ… æ€§èƒ½åŸºå‡†ï¼šä¸ HuggingFace å¯¹æ¯”

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### Baselineï¼ˆQwen3-0.6B on A100ï¼‰

```
FoloVLLM M1:
  - TTFT: 50-80 ms
  - TPOT: 15-20 ms
  - Throughput: 40-60 tokens/s
  - GPU Memory: ~1.2 GB

HuggingFace:
  - Throughput: 50-70 tokens/s
  - GPU Memory: ~1.2 GB

ç›¸å¯¹æ€§èƒ½: 0.8-0.9x (æ¥è¿‘ HF baseline)
```

### ä¼˜åŒ–è®¡åˆ’

| Milestone | ä¼˜åŒ–                | é¢„æœŸæå‡           |
| --------- | ------------------- | ------------------ |
| M2        | Continuous Batching | Throughput 3-5x    |
| M3        | Paged Attention     | æ˜¾å­˜åˆ©ç”¨ç‡ 2-3x    |
| M4        | Flash Attention     | TTFT 2x, TPOT 1.5x |
| M5        | Chunked Prefill     | é•¿åºåˆ— TTFT ä¼˜åŒ–   |

---

## ğŸ“ å­¦ä¹ è·¯å¾„

### æ¨èé˜…è¯»é¡ºåº

1. **å…¥é—¨**ï¼ˆç†è§£åŸç†ï¼‰ï¼š
   - å…ˆçœ‹ [å­¦ä¹ ç¬”è®°](learn/milestone_1.md) ä¸­çš„ "æ ¸å¿ƒæŠ€æœ¯" éƒ¨åˆ†
   - ç†è§£ KV Cache å’Œ Transformer æ¨ç†æµç¨‹

2. **æ·±å…¥**ï¼ˆæŒæ¡å®ç°ï¼‰ï¼š
   - é˜…è¯» [å£è¿°å±•ç¤ºæ–‡æ¡£](presentation/milestone_1.md) äº†è§£æ¯ä¸ªç±»/å‡½æ•°çš„å®ç°ç»†èŠ‚
   - è·Ÿéšå®Œæ•´æ¨ç†æµç¨‹ä¸²è®²ç†è§£æ•°æ®æµåŠ¨

3. **å®è·µ**ï¼ˆåŠ¨æ‰‹è¿è¡Œï¼‰ï¼š
   - è¿è¡Œ `examples/m1_inference.py`
   - é˜…è¯» [å¼€å‘æ—¥å¿—](dev/milestone_1.md) äº†è§£è®¾è®¡å†³ç­–

4. **å·©å›º**ï¼ˆæ·±åŒ–ç†è§£ï¼‰ï¼š
   - æŸ¥çœ‹æµ‹è¯•ä»£ç ç†è§£å„ç»„ä»¶ç”¨æ³•
   - å°è¯•ä¿®æ”¹é‡‡æ ·å‚æ•°è§‚å¯Ÿè¾“å‡ºå˜åŒ–
   - å¯¹ç…§æºç ç†è§£å®ç°ç»†èŠ‚

5. **é¢è¯•å‡†å¤‡**ï¼ˆç³»ç»Ÿå¤ä¹ ï¼‰ï¼š
   - é˜…è¯» [é¢è¯•æŒ‡å—](interview/milestone_1.md) ç³»ç»Ÿå¤ä¹ æ‰€æœ‰çŸ¥è¯†ç‚¹
   - æ¶µç›– 8 å¤§ç±»å…± 40+ ä¸ªé¢è¯•é—®é¢˜åŠè¯¦ç»†è§£ç­”
   - é‡ç‚¹ï¼šKV Cacheã€Attentionã€RoPEã€é‡‡æ ·ç­–ç•¥ã€ç³»ç»Ÿè®¾è®¡

---

## ğŸ”— ç›¸å…³èµ„æº

### å‚è€ƒå®ç°

- **vLLM v1**: `reference/vllm/vllm/v1/`
- **nano-vllm**: `reference/nano-vllm/nanovllm/`

### è®ºæ–‡

1. [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Transformer
2. [RoFormer](https://arxiv.org/abs/2104.09864) - RoPE
3. [Root Mean Square Layer Normalization](https://arxiv.org/abs/1910.07467) - RMSNorm
4. [GQA: Training Generalized Multi-Query Transformer Models](https://arxiv.org/abs/2305.13245) - GQA

### åšå®¢

- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
- [KV Cache Explained](https://kipp.ly/blog/transformer-inference-arithmetic/)

---

## ğŸ’¬ å¸¸è§é—®é¢˜

### Q1: M1 æ”¯æŒå“ªäº›æ¨¡å‹ï¼Ÿ

ç›®å‰ä¸»è¦æ”¯æŒ Qwen3 ç³»åˆ—ï¼Œä»£ç ç»“æ„ä¹Ÿé€‚ç”¨äºå…¶ä»– decoder-only æ¨¡å‹ï¼ˆLLaMAã€GPT-NeoX ç­‰ï¼‰ï¼Œåªéœ€å®ç°å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶ã€‚

### Q2: M1 çš„æ€§èƒ½å¦‚ä½•ï¼Ÿ

M1 æ˜¯ baseline å®ç°ï¼Œæ€§èƒ½ä¸ HuggingFace æ¥è¿‘ï¼ˆ~0.8-0.9xï¼‰ã€‚M2-M4 ä¼šæ˜¾è‘—æå‡æ€§èƒ½ã€‚

### Q3: å¦‚ä½•åˆ‡æ¢åˆ°å…¶ä»–æ¨¡å‹ï¼Ÿ

ä¿®æ”¹ `ModelConfig` ä¸­çš„ `model` å‚æ•°ï¼ŒæŒ‡å‘ HuggingFace ä¸Šçš„æ¨¡å‹åæˆ–æœ¬åœ°è·¯å¾„ã€‚

### Q4: æµ‹è¯•éœ€è¦ GPU å—ï¼Ÿ

å•å…ƒæµ‹è¯•å¤§éƒ¨åˆ†å¯ä»¥åœ¨ CPU è¿è¡Œã€‚é›†æˆæµ‹è¯•å’Œæ€§èƒ½æµ‹è¯•éœ€è¦ GPUã€‚

### Q5: å¦‚ä½•è°ƒè¯•ç”Ÿæˆç»“æœï¼Ÿ

- è®¾ç½® `temperature=0.0` ä½¿ç”¨ greedy sampling è·å¾—ç¡®å®šæ€§è¾“å‡º
- æŸ¥çœ‹ `output.metrics` äº†è§£æ€§èƒ½
- å¯¹æ¯” HuggingFace è¾“å‡ºéªŒè¯æ­£ç¡®æ€§

---

## ğŸš€ ä¸‹ä¸€æ­¥

å®Œæˆ M1 å­¦ä¹ åï¼Œå¯ä»¥ï¼š

1. **æ·±å…¥ç†è§£**ï¼š
   - æŸ¥çœ‹æºç ï¼Œç†è§£æ¯ä¸ªç»„ä»¶çš„å®ç°
   - è¿è¡Œæµ‹è¯•ï¼Œè§‚å¯Ÿå„æ¨¡å—çš„è¡Œä¸º
   - å°è¯•ä¿®æ”¹ä»£ç ï¼ŒåŠ æ·±ç†è§£

2. **å‡†å¤‡ M2**ï¼š
   - é˜…è¯» M2 å¼€å‘è®¡åˆ’
   - äº†è§£ Continuous Batching çš„åŸç†
   - æ€è€ƒå¦‚ä½•æ‰©å±• M1 çš„å•è¯·æ±‚æ¶æ„

3. **è´¡çŒ®é¡¹ç›®**ï¼š
   - æ”¹è¿›æ–‡æ¡£
   - ä¼˜åŒ–ä»£ç 
   - æ·»åŠ æµ‹è¯•
   - æ”¯æŒæ›´å¤šæ¨¡å‹

---

## ğŸ“® åé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼š
- æŸ¥çœ‹æ–‡æ¡£ä¸­çš„è¯¦ç»†è¯´æ˜
- è¿è¡Œæµ‹è¯•éªŒè¯åŠŸèƒ½
- å‚è€ƒç¤ºä¾‹ä»£ç 

---

**ç¥å­¦ä¹ æ„‰å¿«ï¼ğŸ‰**

ä¸‹ä¸€ç«™ï¼š**Milestone 2 - è¿ç»­æ‰¹å¤„ç†**

